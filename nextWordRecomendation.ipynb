{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuRStKgEa7mNkdt1pDx0dx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishektripathi66/RecomendationSystem/blob/main/nextWordRecomendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-xCfN_QTvgJk"
      },
      "outputs": [],
      "source": [
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "SYeWvhj7wuzN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "1L-gJsNRwwzD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "BCfrK_-kw1Gj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "metadata": {
        "id": "0Y3ugytyw3ee"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model"
      ],
      "metadata": {
        "id": "PZ3zasiCxEj4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM, Dense, Activation"
      ],
      "metadata": {
        "id": "ZTLCoImFxSqb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "tbe-viiE7Soh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df = pd.read_csv(\"https://raw.githubusercontent.com/lutzhamel/fake-news/master/data/fake_or_real_news.csv\")"
      ],
      "metadata": {
        "id": "ZCnxqfO0xZmd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# joining all the texts from the csv\n",
        "text= list(text_df.text.values)\n",
        "joined_text = \" \".join(text)"
      ],
      "metadata": {
        "id": "yUiIC46W9ALK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# due to the RAM restriction using only partial word\n",
        "partial_text = joined_text[:100000]"
      ],
      "metadata": {
        "id": "EevOlTLN1etG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing only words and not space and special character\n",
        "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "tokens = tokenizer.tokenize(partial_text.lower())"
      ],
      "metadata": {
        "id": "kpVpcYtX1lIJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_tokens = np.unique(tokens)\n",
        "unique_token_index = {token: idx for idx, token in enumerate(unique_tokens)}\n"
      ],
      "metadata": {
        "id": "-NXm9KBu1Ote"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# words used for making the prediction of next word, keeping it as 1 wont make much sense as it wont give any context\n",
        "n_words = 10\n",
        "input_words = []\n",
        "next_words = []\n",
        "for i in range(len(tokens)-n_words):\n",
        "  input_words.append(tokens[i:i+n_words])\n",
        "  next_words.append(tokens[i+n_words])"
      ],
      "metadata": {
        "id": "f4fxZMuE35Vc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(input_words), n_words,len(unique_tokens)),dtype=bool)\n",
        "y= np.zeros((len(next_words),len(unique_tokens)),dtype=bool)"
      ],
      "metadata": {
        "id": "hY86xSGT64Yv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, words in enumerate(input_words):\n",
        "  for j, word in enumerate(words):\n",
        "    x[i,j, unique_token_index[word]] = 1\n",
        "  y[i, unique_token_index[next_words[i]]] = 1"
      ],
      "metadata": {
        "id": "qxxB-0gcGCLh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128,input_shape=(n_words,len(unique_tokens)),return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(unique_tokens)))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "metadata": {
        "id": "mt6OqIivF7QQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer= RMSprop(learning_rate=0.01), metrics=[\"accuracy\"])\n",
        "model.fit(x,y,batch_size=128,epochs=30, shuffle=True)"
      ],
      "metadata": {
        "id": "QbKfUJ5u5gtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"mymodel.keras\")"
      ],
      "metadata": {
        "id": "dph3lz3k-oU1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"mymodel.keras\")"
      ],
      "metadata": {
        "id": "e8CfLKZ_-v41"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(input_text,n_best):\n",
        "  input_text=input_text.lower()\n",
        "  x= np.zeros((1,n_words,len(unique_tokens)))\n",
        "  for i,word in enumerate(input_text.split()):\n",
        "    x[0,i,unique_token_index[word]]=1\n",
        "\n",
        "  predictions=model.predict(x)[0]\n",
        "  return np.argpartition(predictions,-n_best)[-n_best:]\n",
        "\n"
      ],
      "metadata": {
        "id": "y3rddRNGCqza"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "possible = predict_next_word(\"He will have to look into this thing and he\",5)"
      ],
      "metadata": {
        "id": "Mc1YN7QsTSnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([unique_tokens[idx] for idx in possible])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uChzKHD8TvY4",
        "outputId": "0d9a3102-245c-443c-c72a-510d75e6a6c2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['began', 'manages', 'were', 'will', 'pointing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(input_text,text_length,creativity=3):\n",
        "  word_sequence = input_text.split()\n",
        "  current=0\n",
        "  for _ in range(text_length):\n",
        "    sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
        "    try:\n",
        "      choice=unique_tokens[random.choice(predict_next_word(sub_sequence,creativity))]\n",
        "    except:\n",
        "      choice = random.choice(unique_tokens)\n",
        "    word_sequence.append(choice)\n",
        "    current+=1\n",
        "  return \" \".join(word_sequence)"
      ],
      "metadata": {
        "id": "_Mg_hCLZXY7c"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"He will have to look into this thing and he\",100,5)"
      ],
      "metadata": {
        "id": "q0S_YhG4ZzkE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}