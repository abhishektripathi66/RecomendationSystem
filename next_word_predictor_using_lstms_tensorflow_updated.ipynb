{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishektripathi66/RecomendationSystem/blob/main/next_word_predictor_using_lstms_tensorflow_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow tensorflow-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY0Xyl29TJMn",
        "outputId": "bac5eb35-e21d-4ac5-d98f-3eca01768f94"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py>=3.10.0 (from tensorflow)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ml-dtypes~=0.3.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow)\n",
            "  Downloading keras-3.2.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
            "Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.2.1 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1 tensorflow-text-2.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "bvaYb0aUR4Ec"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "Panel-id show? = PANELID\n",
        "Message-id = MSGID\n",
        "\n",
        "REFLIST\n",
        "REFLISTD\n",
        "REFLISTL\n",
        "REFACTD\n",
        "REFACTL\n",
        "REFOPEND\n",
        "REFOPENL\n",
        "REFADDD\n",
        "REFADDL\n",
        "RETP\n",
        "RETF\n",
        "RETRIEVE\n",
        "CRETRIEV\n",
        "ISRDDN\n",
        "XMIT\n",
        "RECEIVE\n",
        "DSLIST\n",
        "SAVE /VDL\n",
        "QPRINT\n",
        "TSO PROFILE\n",
        "CUT DISPLAY\n",
        "KEYLIST\n",
        "KEYS\n",
        "PFSHOW\n",
        "SCRNAME ON\n",
        "SWAP LIST\n",
        "\n",
        "ASM\n",
        "CALC\n",
        "COBOL\n",
        "FORT\n",
        "\n",
        "CALL\n",
        "LINK\n",
        "LOADGO\n",
        "RUN\n",
        "TEST\n",
        "TESTAUTH\n",
        "\n",
        "ALLOCATE\n",
        "ALTLIB\n",
        "ATTRIB\n",
        "CONVERT\n",
        "COPY\n",
        "DELETE\n",
        "EDIT\n",
        "FORMAT\n",
        "FREE\n",
        "LIST\n",
        "LISTALC\n",
        "LISTBC\n",
        "LISTCAT\n",
        "LISTDS\n",
        "MERGE\n",
        "PRINTDS\n",
        "PROTECT\n",
        "RENAME\n",
        "TSOLIB\n",
        "\n",
        "ACCOUNT\n",
        "CONSOLE\n",
        "OPERATOR\n",
        "PARMLIB\n",
        "RACONVRT\n",
        "SYNC\n",
        "CONSPROF\n",
        "EXEC\n",
        "EXECUTIL\n",
        "HELP\n",
        "LOGOFF\n",
        "LOGON\n",
        "PROFILE\n",
        "SEND\n",
        "TERMINAL\n",
        "TIME\n",
        "TSOEXEC\n",
        "WHEN\n",
        "CANCEL\n",
        "OUTPUT\n",
        "STATUS\n",
        "SUBMIT\n",
        "INTERACTIVE\n",
        "RECEIVE\n",
        "TRANSMIT\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# let's perform some **preprocessing** on text..."
      ],
      "metadata": {
        "id": "-r9xO4jPDtGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Lowercasing the text\n",
        "lowercase_text = text.lower()\n",
        "\n",
        "# Removing extra newlines between sentences\n",
        "cleaned_text = re.sub(r'\\n\\s*\\n', '\\n', lowercase_text)\n",
        "\n",
        "print(\"Lowercased Text with Extra Newlines Removed:\\n\")\n",
        "print(cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiRKPHT9__08",
        "outputId": "1f3989e5-c38d-4985-e6a6-34b8fab2657c"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercased Text with Extra Newlines Removed:\n",
            "\n",
            "\n",
            "panel-id show? = panelid\n",
            "message-id = msgid\n",
            "reflist\n",
            "reflistd\n",
            "reflistl\n",
            "refactd\n",
            "refactl\n",
            "refopend\n",
            "refopenl \n",
            "refaddd\n",
            "refaddl\n",
            "retp\n",
            "retf\n",
            "retrieve\n",
            "cretriev\n",
            "isrddn\n",
            "xmit\n",
            "receive\n",
            "dslist\n",
            "save /vdl\n",
            "qprint\n",
            "tso profile\n",
            "cut display\n",
            "keylist\n",
            "keys\n",
            "pfshow\n",
            "scrname on\n",
            "swap list\n",
            "asm\n",
            "calc\n",
            "cobol\n",
            "fort\n",
            "call\n",
            "link\n",
            "loadgo\n",
            "run\n",
            "test\n",
            "testauth\n",
            "allocate\n",
            "altlib\n",
            "attrib\n",
            "convert\n",
            "copy\n",
            "delete\n",
            "edit\n",
            "format\n",
            "free\n",
            "list\n",
            "listalc\n",
            "listbc\n",
            "listcat\n",
            "listds\n",
            "merge\n",
            "printds\n",
            "protect\n",
            "rename\n",
            "tsolib\n",
            "account\n",
            "console\n",
            "operator\n",
            "parmlib\n",
            "raconvrt\n",
            "sync\n",
            "consprof\n",
            "exec\n",
            "executil\n",
            "help\n",
            "logoff\n",
            "logon\n",
            "profile\n",
            "send\n",
            "terminal\n",
            "time\n",
            "tsoexec\n",
            "when\n",
            "cancel\n",
            "output\n",
            "status\n",
            "submit\n",
            "interactive\n",
            "receive\n",
            "transmit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "abuJfZL_SKSp"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([cleaned_text])"
      ],
      "metadata": {
        "id": "1bdhO7mOSau3"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# to see, what numbers are allocated to what words, there's an attribute name \"word_index\""
      ],
      "metadata": {
        "id": "hxwQ5qIySn1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKv_lSQKSg9U",
        "outputId": "77cb3afe-1524-4555-829f-c82a4c293d1c"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 1,\n",
              " 'receive': 2,\n",
              " 'profile': 3,\n",
              " 'list': 4,\n",
              " 'panel': 5,\n",
              " 'show': 6,\n",
              " 'panelid': 7,\n",
              " 'message': 8,\n",
              " 'msgid': 9,\n",
              " 'reflist': 10,\n",
              " 'reflistd': 11,\n",
              " 'reflistl': 12,\n",
              " 'refactd': 13,\n",
              " 'refactl': 14,\n",
              " 'refopend': 15,\n",
              " 'refopenl': 16,\n",
              " 'refaddd': 17,\n",
              " 'refaddl': 18,\n",
              " 'retp': 19,\n",
              " 'retf': 20,\n",
              " 'retrieve': 21,\n",
              " 'cretriev': 22,\n",
              " 'isrddn': 23,\n",
              " 'xmit': 24,\n",
              " 'dslist': 25,\n",
              " 'save': 26,\n",
              " 'vdl': 27,\n",
              " 'qprint': 28,\n",
              " 'tso': 29,\n",
              " 'cut': 30,\n",
              " 'display': 31,\n",
              " 'keylist': 32,\n",
              " 'keys': 33,\n",
              " 'pfshow': 34,\n",
              " 'scrname': 35,\n",
              " 'on': 36,\n",
              " 'swap': 37,\n",
              " 'asm': 38,\n",
              " 'calc': 39,\n",
              " 'cobol': 40,\n",
              " 'fort': 41,\n",
              " 'call': 42,\n",
              " 'link': 43,\n",
              " 'loadgo': 44,\n",
              " 'run': 45,\n",
              " 'test': 46,\n",
              " 'testauth': 47,\n",
              " 'allocate': 48,\n",
              " 'altlib': 49,\n",
              " 'attrib': 50,\n",
              " 'convert': 51,\n",
              " 'copy': 52,\n",
              " 'delete': 53,\n",
              " 'edit': 54,\n",
              " 'format': 55,\n",
              " 'free': 56,\n",
              " 'listalc': 57,\n",
              " 'listbc': 58,\n",
              " 'listcat': 59,\n",
              " 'listds': 60,\n",
              " 'merge': 61,\n",
              " 'printds': 62,\n",
              " 'protect': 63,\n",
              " 'rename': 64,\n",
              " 'tsolib': 65,\n",
              " 'account': 66,\n",
              " 'console': 67,\n",
              " 'operator': 68,\n",
              " 'parmlib': 69,\n",
              " 'raconvrt': 70,\n",
              " 'sync': 71,\n",
              " 'consprof': 72,\n",
              " 'exec': 73,\n",
              " 'executil': 74,\n",
              " 'help': 75,\n",
              " 'logoff': 76,\n",
              " 'logon': 77,\n",
              " 'send': 78,\n",
              " 'terminal': 79,\n",
              " 'time': 80,\n",
              " 'tsoexec': 81,\n",
              " 'when': 82,\n",
              " 'cancel': 83,\n",
              " 'output': 84,\n",
              " 'status': 85,\n",
              " 'submit': 86,\n",
              " 'interactive': 87,\n",
              " 'transmit': 88}"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now we'll try to create a dataset from this text as a supervised learning task dataset, where there's an input and an output\n",
        "> ### for ex. if text = \"How are you all?\"\n",
        "===========================================\n",
        "> ### Input: **How**\n",
        "> ### Output: **are**\n",
        "===========================================\n",
        "> ### Input: **How are**\n",
        "> ### Output: **you** and so on..."
      ],
      "metadata": {
        "id": "GUz4ZfvTTl2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in cleaned_text.split(\"\\n\"):\n",
        "    # convert words into numbers\n",
        "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    print(tokenized_sentence)\n",
        "\n",
        "    for i in range(1, len(tokenized_sentence)):\n",
        "        input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAC4gaFqSyFo",
        "outputId": "08280802-27f8-4e90-849c-9713913d19a2"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[5, 1, 6, 7]\n",
            "[8, 1, 9]\n",
            "[10]\n",
            "[11]\n",
            "[12]\n",
            "[13]\n",
            "[14]\n",
            "[15]\n",
            "[16]\n",
            "[17]\n",
            "[18]\n",
            "[19]\n",
            "[20]\n",
            "[21]\n",
            "[22]\n",
            "[23]\n",
            "[24]\n",
            "[2]\n",
            "[25]\n",
            "[26, 27]\n",
            "[28]\n",
            "[29, 3]\n",
            "[30, 31]\n",
            "[32]\n",
            "[33]\n",
            "[34]\n",
            "[35, 36]\n",
            "[37, 4]\n",
            "[38]\n",
            "[39]\n",
            "[40]\n",
            "[41]\n",
            "[42]\n",
            "[43]\n",
            "[44]\n",
            "[45]\n",
            "[46]\n",
            "[47]\n",
            "[48]\n",
            "[49]\n",
            "[50]\n",
            "[51]\n",
            "[52]\n",
            "[53]\n",
            "[54]\n",
            "[55]\n",
            "[56]\n",
            "[4]\n",
            "[57]\n",
            "[58]\n",
            "[59]\n",
            "[60]\n",
            "[61]\n",
            "[62]\n",
            "[63]\n",
            "[64]\n",
            "[65]\n",
            "[66]\n",
            "[67]\n",
            "[68]\n",
            "[69]\n",
            "[70]\n",
            "[71]\n",
            "[72]\n",
            "[73]\n",
            "[74]\n",
            "[75]\n",
            "[76]\n",
            "[77]\n",
            "[3]\n",
            "[78]\n",
            "[79]\n",
            "[80]\n",
            "[81]\n",
            "[82]\n",
            "[83]\n",
            "[84]\n",
            "[85]\n",
            "[86]\n",
            "[87]\n",
            "[2]\n",
            "[88]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# the input shape must be same when passing the sequences into the neural networks, so for that we will applying **padding** in front of every sentence with respect to which sentence has max. number of words."
      ],
      "metadata": {
        "id": "TAZj2P2HgJnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(x) for x in input_sequences])\n",
        "max_length # there present a sentence which has maximum 111 words."
      ],
      "metadata": {
        "id": "OtGMB4NqdOYK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfe98003-1d49-4812-8840-12598c8c15de"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now we'll apply **zero_padding**"
      ],
      "metadata": {
        "id": "_LkltLXohC6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "PTQTuQ32f3dQ"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences = pad_sequences(input_sequences, maxlen=max_length, padding='pre')"
      ],
      "metadata": {
        "id": "UwGq33BqzIq7"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtDnNxWghhfU",
        "outputId": "aec541bb-7433-4526-91d2-4f4a1d6d55fd"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  5,  1],\n",
              "       [ 0,  5,  1,  6],\n",
              "       [ 5,  1,  6,  7],\n",
              "       [ 0,  0,  8,  1],\n",
              "       [ 0,  8,  1,  9],\n",
              "       [ 0,  0, 26, 27],\n",
              "       [ 0,  0, 29,  3],\n",
              "       [ 0,  0, 30, 31],\n",
              "       [ 0,  0, 35, 36],\n",
              "       [ 0,  0, 37,  4]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = input_sequences[:-1]\n",
        "y = input_sequences[:]"
      ],
      "metadata": {
        "id": "hGlBl6FQhsFM"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB13TA8kiD9E",
        "outputId": "be20d961-43de-43a7-d0cd-b4358fcdced9"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 1],\n",
              " [5, 1, 6],\n",
              " [5, 1, 6, 7],\n",
              " [8, 1],\n",
              " [8, 1, 9],\n",
              " [26, 27],\n",
              " [29, 3],\n",
              " [30, 31],\n",
              " [35, 36]]"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rit_y8_AiEa5",
        "outputId": "a8b656b9-2d2a-4746-cbf8-eea63e5c0994"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 1],\n",
              " [5, 1, 6],\n",
              " [5, 1, 6, 7],\n",
              " [8, 1],\n",
              " [8, 1, 9],\n",
              " [26, 27],\n",
              " [29, 3],\n",
              " [30, 31],\n",
              " [35, 36],\n",
              " [37, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now from our dataset (X and y), as we have **discrete values**, we can use **multi-class classification.**"
      ],
      "metadata": {
        "id": "FOfaokwOkeui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "eVWOTRdWj9S7",
        "outputId": "b1dd65af-a0b4-40cd-b277-f2ff16b5c883"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-149-e6f96141e8d5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### X.shape = (1478, 110) => means **in each sentence there are 110 words** and there are **total 1478 sentences**."
      ],
      "metadata": {
        "id": "rjFmOA_lDcou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now we'll **ONE HOT ENCODE** the y, which is currently a scaler."
      ],
      "metadata": {
        "id": "5hG4BaePlabZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y = to_categorical(y, num_classes=len(tokenizer.word_index)+1)\n",
        "# +1 because OHE starts from 0 and word_index returned output started from 1"
      ],
      "metadata": {
        "id": "Xu4IgH-1lJ0V"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape     # (1478, 535), 535 because there are total 535 words in our vocabulary."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXsqWBbVlzl9",
        "outputId": "2084dd0d-4370-4e82-89ec-9c17f4e48a5a"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 89)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " y_rows, y_cols = y.shape"
      ],
      "metadata": {
        "id": "Omu277nJKZn2"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y   # each sentence is represented by a sparse vector having 535 values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFnle3xOmcM1",
        "outputId": "80f4dde2-1ccb-4ffb-ab88-51d6a7a93102"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we're reading with **TRAINING THE DATA**"
      ],
      "metadata": {
        "id": "L6V8VmKAmsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, SimpleRNN, GRU, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta, Ftrl, Nadam, Adamax\n",
        "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy, mean_squared_error, mean_absolute_error, huber, logcosh, poisson, cosine_similarity\n",
        "# from tensorflow.keras.metrics import accuracy, binary_accuracy, categorical_accuracy, top_k_categorical_accuracy, sparse_categorical_accuracy, mean_io_u, precision"
      ],
      "metadata": {
        "id": "NwwJUxTimr7P"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_units = 256\n",
        "activation1 = 'softmax'\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=y_cols, output_dim=max_length))\n",
        "# there are total 535 words in our vocabulary and 110 is the length of each sentence\n",
        "# model.add(LSTM(units=256))\n",
        "model.add(GRU(hidden_units, input_shape=y.shape))\n",
        "# model.add(Dense(units=y_cols, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(y_cols, activation='softplus'))\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Dense(y_cols, activation='relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Dense(y_cols, activation='swish'))\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Dense(units=y_cols, activation='softmax'))\n",
        "\n",
        "model.compile(loss='cosine_similarity',\n",
        "              optimizer=Adamax(learning_rate=0.01),\n",
        "              metrics=['cosine_similarity'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=\"cosine_similarity\", patience=100, restore_best_weights=True)\n",
        "history = model.fit(X, y, epochs=200, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOvBN3fFmowp",
        "outputId": "b88ea455-a97a-433b-9bb8-d7157f26aeb9"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - cosine_similarity: 0.1051 - loss: -0.1051\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - cosine_similarity: 0.2413 - loss: -0.2413\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - cosine_similarity: 0.2939 - loss: -0.2939\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - cosine_similarity: 0.3262 - loss: -0.3262\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - cosine_similarity: 0.3133 - loss: -0.3133\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - cosine_similarity: 0.3164 - loss: -0.3164\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - cosine_similarity: 0.3316 - loss: -0.3316\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - cosine_similarity: 0.3358 - loss: -0.3358\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - cosine_similarity: 0.3340 - loss: -0.3340\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 0.3336 - loss: -0.3336\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 0.3383 - loss: -0.3383\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 0.3409 - loss: -0.3409\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 0.3478 - loss: -0.3478\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - cosine_similarity: 0.3508 - loss: -0.3508\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - cosine_similarity: 0.3517 - loss: -0.3517\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - cosine_similarity: 0.3516 - loss: -0.3516\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - cosine_similarity: 0.3538 - loss: -0.3538\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - cosine_similarity: 0.3560 - loss: -0.3560\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.3602 - loss: -0.3602\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - cosine_similarity: 0.3684 - loss: -0.3684\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - cosine_similarity: 0.3788 - loss: -0.3788\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - cosine_similarity: 0.3833 - loss: -0.3833\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 0.3971 - loss: -0.3971\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - cosine_similarity: 0.4175 - loss: -0.4175\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.4365 - loss: -0.4365\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - cosine_similarity: 0.4626 - loss: -0.4626\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.5011 - loss: -0.5011\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 0.5313 - loss: -0.5313\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 0.5580 - loss: -0.5580\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 0.5949 - loss: -0.5949\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 0.6398 - loss: -0.6398\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.6276 - loss: -0.6276\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - cosine_similarity: 0.6935 - loss: -0.6935\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - cosine_similarity: 0.7054 - loss: -0.7054\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - cosine_similarity: 0.7378 - loss: -0.7378\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - cosine_similarity: 0.7457 - loss: -0.7457\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 0.7648 - loss: -0.7648\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 0.7870 - loss: -0.7870\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 0.7902 - loss: -0.7902\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - cosine_similarity: 0.8267 - loss: -0.8267\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - cosine_similarity: 0.8437 - loss: -0.8437\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - cosine_similarity: 0.8356 - loss: -0.8356\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - cosine_similarity: 0.8608 - loss: -0.8608\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 0.8891 - loss: -0.8891\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - cosine_similarity: 0.8484 - loss: -0.8484\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - cosine_similarity: 0.9042 - loss: -0.9042\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - cosine_similarity: 0.8769 - loss: -0.8769\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - cosine_similarity: 0.9266 - loss: -0.9266\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - cosine_similarity: 0.9217 - loss: -0.9217\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - cosine_similarity: 0.8969 - loss: -0.8969\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - cosine_similarity: 0.9367 - loss: -0.9367\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - cosine_similarity: 0.9352 - loss: -0.9352\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - cosine_similarity: 0.9135 - loss: -0.9135\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.9427 - loss: -0.9427\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - cosine_similarity: 0.9519 - loss: -0.9519\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - cosine_similarity: 0.9455 - loss: -0.9455\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - cosine_similarity: 0.9541 - loss: -0.9541\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - cosine_similarity: 0.8905 - loss: -0.8905\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - cosine_similarity: 0.9531 - loss: -0.9531\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - cosine_similarity: 0.9759 - loss: -0.9759\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - cosine_similarity: 0.9808 - loss: -0.9808\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 0.9904 - loss: -0.9904\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - cosine_similarity: 0.9761 - loss: -0.9761\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - cosine_similarity: 0.9833 - loss: -0.9833\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - cosine_similarity: 0.9773 - loss: -0.9773\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 0.9925 - loss: -0.9925\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.9959 - loss: -0.9959\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 0.9929 - loss: -0.9929\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - cosine_similarity: 0.9917 - loss: -0.9917\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - cosine_similarity: 0.9920 - loss: -0.9920\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - cosine_similarity: 0.9966 - loss: -0.9966\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.9970 - loss: -0.9970\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - cosine_similarity: 0.9931 - loss: -0.9931\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 0.9954 - loss: -0.9954\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - cosine_similarity: 0.9964 - loss: -0.9964\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - cosine_similarity: 0.9982 - loss: -0.9982\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - cosine_similarity: 0.9978 - loss: -0.9978\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.9977 - loss: -0.9977\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - cosine_similarity: 0.9962 - loss: -0.9962\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - cosine_similarity: 0.9985 - loss: -0.9985\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 0.9984 - loss: -0.9984\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - cosine_similarity: 0.9974 - loss: -0.9974\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - cosine_similarity: 0.9982 - loss: -0.9982\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 0.9987 - loss: -0.9987\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 0.9988 - loss: -0.9988\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 0.9986 - loss: -0.9986\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - cosine_similarity: 0.9989 - loss: -0.9989\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - cosine_similarity: 0.9984 - loss: -0.9984\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - cosine_similarity: 0.9990 - loss: -0.9990\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.9996 - loss: -0.9996\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 0.9997 - loss: -0.9997\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - cosine_similarity: 0.9992 - loss: -0.9992\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 0.9994 - loss: -0.9994\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - cosine_similarity: 0.9995 - loss: -0.9995\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.9997 - loss: -0.9997\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - cosine_similarity: 0.9997 - loss: -0.9997\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.9992 - loss: -0.9992\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.9997 - loss: -0.9997\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 115/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 116/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - cosine_similarity: 0.9997 - loss: -0.9997\n",
            "Epoch 117/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 118/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 119/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 120/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 121/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 122/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 123/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 124/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 125/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - cosine_similarity: 0.9995 - loss: -0.9995\n",
            "Epoch 126/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 127/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 128/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 129/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 130/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 131/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 132/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 133/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 134/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 135/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 136/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 137/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 138/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 139/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 140/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 141/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 142/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 143/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 144/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 145/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 146/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 147/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 148/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 149/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 150/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 151/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 152/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 153/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 154/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 155/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 156/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 157/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 158/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 159/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 160/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 161/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 162/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 163/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 164/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 165/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 166/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 167/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 168/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 169/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 170/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 171/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 172/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 173/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 174/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 175/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 176/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 177/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 178/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 179/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 180/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 181/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 182/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 183/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 184/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 185/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 186/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 187/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 188/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 189/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 190/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 191/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - cosine_similarity: 0.9998 - loss: -0.9998\n",
            "Epoch 192/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 193/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 194/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 195/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 196/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 197/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - cosine_similarity: 0.9999 - loss: -0.9999\n",
            "Epoch 198/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 199/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n",
            "Epoch 200/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - cosine_similarity: 1.0000 - loss: -1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Knowing the summary of the model..."
      ],
      "metadata": {
        "id": "T1ThjNg--KtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "DlYmybJBrFrL",
        "outputId": "9a1b7f53-e7e5-47d3-aa3a-a29873b69400"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_17 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m4\u001b[0m)                │             \u001b[38;5;34m356\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_17 (\u001b[38;5;33mGRU\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m201,216\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_17 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_58 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m)                  │          \u001b[38;5;34m22,873\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m)                  │           \u001b[38;5;34m8,010\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m)                  │           \u001b[38;5;34m8,010\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m)                  │           \u001b[38;5;34m8,010\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">356</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">201,216</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">22,873</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,010</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,010</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,010</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m745,427\u001b[0m (2.84 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">745,427</span> (2.84 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m248,475\u001b[0m (970.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">248,475</span> (970.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m496,952\u001b[0m (1.90 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">496,952</span> (1.90 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's plot accuracy v/s loss curve"
      ],
      "metadata": {
        "id": "sYVkpqPh-VcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plot_1 = pd.DataFrame(history.history)\n",
        "plt.figure(dpi=150, figsize = (5,3))\n",
        "plt.plot(plot_1)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(plot_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "Qcp1n9gvekcX",
        "outputId": "9ee6bf82-2e32-48a2-f897-22d8a193db71"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fba5a1e23e0>"
            ]
          },
          "metadata": {},
          "execution_count": 152
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 750x450 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finally let's watch the output on giving **LLMs are** as an input..."
      ],
      "metadata": {
        "id": "B3E648yV-a5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "z-V0rPiU68l5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"LLMs are\"\n",
        "\n",
        "for i in range(6):\n",
        "    previousword = text.split(\" \")[-1]\n",
        "    # tokenize\n",
        "    token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "    print(token_text)\n",
        "    # padding\n",
        "    padded_token_text = pad_sequences([token_text], maxlen=max_length, padding='pre')\n",
        "    print(padded_token_text)\n",
        "    # predict\n",
        "    position = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "    # print word at the particular position in tokenizer.word_index\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == position:\n",
        "            text = text + \" \" + word\n",
        "            print(text)\n",
        "            time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88sCwok_24ps",
        "outputId": "fb3728fe-3fd6-4049-9bfd-781a4aebe6d5"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[[0 0 0 0]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
            "LLMs are on\n",
            "[36]\n",
            "[[ 0  0  0 36]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "LLMs are on id\n",
            "[36, 1]\n",
            "[[ 0  0 36  1]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "LLMs are on id id\n",
            "[36, 1, 1]\n",
            "[[ 0 36  1  1]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "LLMs are on id id panelid\n",
            "[36, 1, 1, 7]\n",
            "[[36  1  1  7]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "LLMs are on id id panelid panelid\n",
            "[36, 1, 1, 7, 7]\n",
            "[[1 1 7 7]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "LLMs are on id id panelid panelid panelid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I think it's performing well :)"
      ],
      "metadata": {
        "id": "brxH57Ho-mz_"
      }
    }
  ]
}