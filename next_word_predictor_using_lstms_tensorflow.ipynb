{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishektripathi66/RecomendationSystem/blob/main/next_word_predictor_using_lstms_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow tensorflow-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY0Xyl29TJMn",
        "outputId": "ab01b90e-5d16-4d58-ec7f-020a046aeb12"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py>=3.10.0 (from tensorflow)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ml-dtypes~=0.3.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow)\n",
            "  Downloading keras-3.2.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
            "Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.2.1 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1 tensorflow-text-2.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bvaYb0aUR4Ec"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Abhishek is a very good boy.\n",
        "Abhishek is kind.\n",
        "Abhishek is well.\n",
        "Abhishek is fine.\n",
        "I am studying in Delhi Technological University.\n",
        "I am living in Delhi.\n",
        "I am a self learner.\n",
        "I want to learn new skills everyday.\n",
        "I go to walk early in the morning.\n",
        "Do you want to tour in UK.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# let's perform some **preprocessing** on text..."
      ],
      "metadata": {
        "id": "-r9xO4jPDtGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Lowercasing the text\n",
        "lowercase_text = text.lower()\n",
        "\n",
        "# Removing extra newlines between sentences\n",
        "cleaned_text = re.sub(r'\\n\\s*\\n', '\\n', lowercase_text)\n",
        "\n",
        "print(\"Lowercased Text with Extra Newlines Removed:\\n\")\n",
        "print(cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiRKPHT9__08",
        "outputId": "14fe120d-2ff1-4e26-aa3b-f778e0b35f03"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercased Text with Extra Newlines Removed:\n",
            "\n",
            "abhishek is a very good boy. \n",
            "abhishek is kind.\n",
            "abhishek is well.\n",
            "abhishek is fine.\n",
            "i am studying in delhi technological university.\n",
            "i am living in delhi.\n",
            "i am a self learner.\n",
            "i want to learn new skills everyday.\n",
            "i go to walk early in the morning.\n",
            "do you want to tour in uk.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "abuJfZL_SKSp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([cleaned_text])"
      ],
      "metadata": {
        "id": "1bdhO7mOSau3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# to see, what numbers are allocated to what words, there's an attribute name \"word_index\""
      ],
      "metadata": {
        "id": "hxwQ5qIySn1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKv_lSQKSg9U",
        "outputId": "722068b4-6c37-4394-ab10-567baccea769"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'i': 1,\n",
              " 'abhishek': 2,\n",
              " 'is': 3,\n",
              " 'in': 4,\n",
              " 'am': 5,\n",
              " 'to': 6,\n",
              " 'a': 7,\n",
              " 'delhi': 8,\n",
              " 'want': 9,\n",
              " 'very': 10,\n",
              " 'good': 11,\n",
              " 'boy': 12,\n",
              " 'kind': 13,\n",
              " 'well': 14,\n",
              " 'fine': 15,\n",
              " 'studying': 16,\n",
              " 'technological': 17,\n",
              " 'university': 18,\n",
              " 'living': 19,\n",
              " 'self': 20,\n",
              " 'learner': 21,\n",
              " 'learn': 22,\n",
              " 'new': 23,\n",
              " 'skills': 24,\n",
              " 'everyday': 25,\n",
              " 'go': 26,\n",
              " 'walk': 27,\n",
              " 'early': 28,\n",
              " 'the': 29,\n",
              " 'morning': 30,\n",
              " 'do': 31,\n",
              " 'you': 32,\n",
              " 'tour': 33,\n",
              " 'uk': 34}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now we'll try to create a dataset from this text as a supervised learning task dataset, where there's an input and an output\n",
        "> ### for ex. if text = \"How are you all?\"\n",
        "===========================================\n",
        "> ### Input: **How**\n",
        "> ### Output: **are**\n",
        "===========================================\n",
        "> ### Input: **How are**\n",
        "> ### Output: **you** and so on..."
      ],
      "metadata": {
        "id": "GUz4ZfvTTl2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in cleaned_text.split(\"\\n\"):\n",
        "    # convert words into numbers\n",
        "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    print(tokenized_sentence)\n",
        "\n",
        "    for i in range(1, len(tokenized_sentence)):\n",
        "        input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAC4gaFqSyFo",
        "outputId": "0d8b3084-36e2-4856-b211-1d3cf21bba19"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 7, 10, 11, 12]\n",
            "[2, 3, 13]\n",
            "[2, 3, 14]\n",
            "[2, 3, 15]\n",
            "[1, 5, 16, 4, 8, 17, 18]\n",
            "[1, 5, 19, 4, 8]\n",
            "[1, 5, 7, 20, 21]\n",
            "[1, 9, 6, 22, 23, 24, 25]\n",
            "[1, 26, 6, 27, 28, 4, 29, 30]\n",
            "[31, 32, 9, 6, 33, 4, 34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# the input shape must be same when passing the sequences into the neural networks, so for that we will applying **padding** in front of every sentence with respect to which sentence has max. number of words."
      ],
      "metadata": {
        "id": "TAZj2P2HgJnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(x) for x in input_sequences])\n",
        "max_length # there present a sentence which has maximum 111 words."
      ],
      "metadata": {
        "id": "OtGMB4NqdOYK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5975f18-da69-4ae3-f297-926e870c3c3d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now we'll apply **zero_padding**"
      ],
      "metadata": {
        "id": "_LkltLXohC6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "PTQTuQ32f3dQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences = pad_sequences(input_sequences, maxlen=max_length, padding='pre')"
      ],
      "metadata": {
        "id": "UwGq33BqzIq7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtDnNxWghhfU",
        "outputId": "12543ad3-c1f2-4bc3-e16d-5848933c769e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  2,  3],\n",
              "       [ 0,  0,  0,  0,  0,  2,  3,  7],\n",
              "       [ 0,  0,  0,  0,  2,  3,  7, 10],\n",
              "       [ 0,  0,  0,  2,  3,  7, 10, 11],\n",
              "       [ 0,  0,  2,  3,  7, 10, 11, 12],\n",
              "       [ 0,  0,  0,  0,  0,  0,  2,  3],\n",
              "       [ 0,  0,  0,  0,  0,  2,  3, 13],\n",
              "       [ 0,  0,  0,  0,  0,  0,  2,  3],\n",
              "       [ 0,  0,  0,  0,  0,  2,  3, 14],\n",
              "       [ 0,  0,  0,  0,  0,  0,  2,  3],\n",
              "       [ 0,  0,  0,  0,  0,  2,  3, 15],\n",
              "       [ 0,  0,  0,  0,  0,  0,  1,  5],\n",
              "       [ 0,  0,  0,  0,  0,  1,  5, 16],\n",
              "       [ 0,  0,  0,  0,  1,  5, 16,  4],\n",
              "       [ 0,  0,  0,  1,  5, 16,  4,  8],\n",
              "       [ 0,  0,  1,  5, 16,  4,  8, 17],\n",
              "       [ 0,  1,  5, 16,  4,  8, 17, 18],\n",
              "       [ 0,  0,  0,  0,  0,  0,  1,  5],\n",
              "       [ 0,  0,  0,  0,  0,  1,  5, 19],\n",
              "       [ 0,  0,  0,  0,  1,  5, 19,  4],\n",
              "       [ 0,  0,  0,  1,  5, 19,  4,  8],\n",
              "       [ 0,  0,  0,  0,  0,  0,  1,  5],\n",
              "       [ 0,  0,  0,  0,  0,  1,  5,  7],\n",
              "       [ 0,  0,  0,  0,  1,  5,  7, 20],\n",
              "       [ 0,  0,  0,  1,  5,  7, 20, 21],\n",
              "       [ 0,  0,  0,  0,  0,  0,  1,  9],\n",
              "       [ 0,  0,  0,  0,  0,  1,  9,  6],\n",
              "       [ 0,  0,  0,  0,  1,  9,  6, 22],\n",
              "       [ 0,  0,  0,  1,  9,  6, 22, 23],\n",
              "       [ 0,  0,  1,  9,  6, 22, 23, 24],\n",
              "       [ 0,  1,  9,  6, 22, 23, 24, 25],\n",
              "       [ 0,  0,  0,  0,  0,  0,  1, 26],\n",
              "       [ 0,  0,  0,  0,  0,  1, 26,  6],\n",
              "       [ 0,  0,  0,  0,  1, 26,  6, 27],\n",
              "       [ 0,  0,  0,  1, 26,  6, 27, 28],\n",
              "       [ 0,  0,  1, 26,  6, 27, 28,  4],\n",
              "       [ 0,  1, 26,  6, 27, 28,  4, 29],\n",
              "       [ 1, 26,  6, 27, 28,  4, 29, 30],\n",
              "       [ 0,  0,  0,  0,  0,  0, 31, 32],\n",
              "       [ 0,  0,  0,  0,  0, 31, 32,  9],\n",
              "       [ 0,  0,  0,  0, 31, 32,  9,  6],\n",
              "       [ 0,  0,  0, 31, 32,  9,  6, 33],\n",
              "       [ 0,  0, 31, 32,  9,  6, 33,  4],\n",
              "       [ 0, 31, 32,  9,  6, 33,  4, 34]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]\n",
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "hGlBl6FQhsFM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB13TA8kiD9E",
        "outputId": "9a1d8d51-123f-4472-cd41-9f212a271d20"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  2],\n",
              "       [ 0,  0,  0,  0,  0,  2,  3],\n",
              "       [ 0,  0,  0,  0,  2,  3,  7],\n",
              "       [ 0,  0,  0,  2,  3,  7, 10],\n",
              "       [ 0,  0,  2,  3,  7, 10, 11],\n",
              "       [ 0,  0,  0,  0,  0,  0,  2],\n",
              "       [ 0,  0,  0,  0,  0,  2,  3],\n",
              "       [ 0,  0,  0,  0,  0,  0,  2],\n",
              "       [ 0,  0,  0,  0,  0,  2,  3],\n",
              "       [ 0,  0,  0,  0,  0,  0,  2],\n",
              "       [ 0,  0,  0,  0,  0,  2,  3],\n",
              "       [ 0,  0,  0,  0,  0,  0,  1],\n",
              "       [ 0,  0,  0,  0,  0,  1,  5],\n",
              "       [ 0,  0,  0,  0,  1,  5, 16],\n",
              "       [ 0,  0,  0,  1,  5, 16,  4],\n",
              "       [ 0,  0,  1,  5, 16,  4,  8],\n",
              "       [ 0,  1,  5, 16,  4,  8, 17],\n",
              "       [ 0,  0,  0,  0,  0,  0,  1],\n",
              "       [ 0,  0,  0,  0,  0,  1,  5],\n",
              "       [ 0,  0,  0,  0,  1,  5, 19],\n",
              "       [ 0,  0,  0,  1,  5, 19,  4],\n",
              "       [ 0,  0,  0,  0,  0,  0,  1],\n",
              "       [ 0,  0,  0,  0,  0,  1,  5],\n",
              "       [ 0,  0,  0,  0,  1,  5,  7],\n",
              "       [ 0,  0,  0,  1,  5,  7, 20],\n",
              "       [ 0,  0,  0,  0,  0,  0,  1],\n",
              "       [ 0,  0,  0,  0,  0,  1,  9],\n",
              "       [ 0,  0,  0,  0,  1,  9,  6],\n",
              "       [ 0,  0,  0,  1,  9,  6, 22],\n",
              "       [ 0,  0,  1,  9,  6, 22, 23],\n",
              "       [ 0,  1,  9,  6, 22, 23, 24],\n",
              "       [ 0,  0,  0,  0,  0,  0,  1],\n",
              "       [ 0,  0,  0,  0,  0,  1, 26],\n",
              "       [ 0,  0,  0,  0,  1, 26,  6],\n",
              "       [ 0,  0,  0,  1, 26,  6, 27],\n",
              "       [ 0,  0,  1, 26,  6, 27, 28],\n",
              "       [ 0,  1, 26,  6, 27, 28,  4],\n",
              "       [ 1, 26,  6, 27, 28,  4, 29],\n",
              "       [ 0,  0,  0,  0,  0,  0, 31],\n",
              "       [ 0,  0,  0,  0,  0, 31, 32],\n",
              "       [ 0,  0,  0,  0, 31, 32,  9],\n",
              "       [ 0,  0,  0, 31, 32,  9,  6],\n",
              "       [ 0,  0, 31, 32,  9,  6, 33],\n",
              "       [ 0, 31, 32,  9,  6, 33,  4]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rit_y8_AiEa5",
        "outputId": "9f14124e-6053-4b67-e14e-7421805ec477"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  7, 10, 11, 12,  3, 13,  3, 14,  3, 15,  5, 16,  4,  8, 17, 18,\n",
              "        5, 19,  4,  8,  5,  7, 20, 21,  9,  6, 22, 23, 24, 25, 26,  6, 27,\n",
              "       28,  4, 29, 30, 32,  9,  6, 33,  4, 34], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now from our dataset (X and y), as we have **discrete values**, we can use **multi-class classification.**"
      ],
      "metadata": {
        "id": "FOfaokwOkeui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVWOTRdWj9S7",
        "outputId": "3216f5eb-f2c0-43dd-fefd-c157ec473062"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((44, 7), (44,))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### X.shape = (1478, 110) => means **in each sentence there are 110 words** and there are **total 1478 sentences**."
      ],
      "metadata": {
        "id": "rjFmOA_lDcou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now we'll **ONE HOT ENCODE** the y, which is currently a scaler."
      ],
      "metadata": {
        "id": "5hG4BaePlabZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y = to_categorical(y, num_classes=len(tokenizer.word_index)+1)\n",
        "# +1 because OHE starts from 0 and word_index returned output started from 1"
      ],
      "metadata": {
        "id": "Xu4IgH-1lJ0V"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape     # (1478, 535), 535 because there are total 535 words in our vocabulary."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXsqWBbVlzl9",
        "outputId": "20fda9d8-5c03-4590-818e-2ae0e84ce429"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44, 35)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " y_rows, y_cols = y.shape"
      ],
      "metadata": {
        "id": "Omu277nJKZn2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y   # each sentence is represented by a sparse vector having 535 values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFnle3xOmcM1",
        "outputId": "cd448f83-8aac-400e-e932-d7bc56c19601"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we're reading with **TRAINING THE DATA**"
      ],
      "metadata": {
        "id": "L6V8VmKAmsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "NwwJUxTimr7P"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=y_cols, output_dim=max_length))\n",
        "# there are total 535 words in our vocabulary and 110 is the length of each sentence\n",
        "model.add(LSTM(units=256))\n",
        "model.add(Dense(units=y_cols, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=\"accuracy\", patience=100, restore_best_weights=True)\n",
        "history = model.fit(X, y, epochs=200, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOvBN3fFmowp",
        "outputId": "a6a03467-0931-4938-a9a6-5bbf293b36d0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.0152 - loss: 3.5559  \n",
            "Epoch 2/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0407 - loss: 3.4771\n",
            "Epoch 3/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0767 - loss: 3.3677\n",
            "Epoch 4/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0767 - loss: 3.3420\n",
            "Epoch 5/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1117 - loss: 3.2674\n",
            "Epoch 6/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1326 - loss: 3.1757\n",
            "Epoch 7/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2093 - loss: 3.0361 \n",
            "Epoch 8/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1326 - loss: 3.0851 \n",
            "Epoch 9/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3068 - loss: 2.9304\n",
            "Epoch 10/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1733 - loss: 2.7682 \n",
            "Epoch 11/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2500 - loss: 2.7187\n",
            "Epoch 12/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2339 - loss: 2.6332 \n",
            "Epoch 13/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3163 - loss: 2.4297 \n",
            "Epoch 14/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3220 - loss: 2.2357\n",
            "Epoch 15/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3731 - loss: 2.0420\n",
            "Epoch 16/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3778 - loss: 1.8368\n",
            "Epoch 17/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3883 - loss: 1.8348 \n",
            "Epoch 18/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4441 - loss: 1.6935\n",
            "Epoch 19/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5047 - loss: 1.5753\n",
            "Epoch 20/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5511 - loss: 1.5267 \n",
            "Epoch 21/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5606 - loss: 1.4670\n",
            "Epoch 22/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6174 - loss: 1.1132 \n",
            "Epoch 23/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5710 - loss: 1.0896\n",
            "Epoch 24/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7045 - loss: 0.8898\n",
            "Epoch 25/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7453 - loss: 0.7971\n",
            "Epoch 26/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7756 - loss: 0.7334\n",
            "Epoch 27/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7708 - loss: 0.7038 \n",
            "Epoch 28/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7500 - loss: 0.7252 \n",
            "Epoch 29/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7093 - loss: 0.6997\n",
            "Epoch 30/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7036 - loss: 0.8210\n",
            "Epoch 31/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7348 - loss: 0.6015 \n",
            "Epoch 32/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7093 - loss: 0.5900 \n",
            "Epoch 33/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8267 - loss: 0.5077\n",
            "Epoch 34/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7652 - loss: 0.5133\n",
            "Epoch 35/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7292 - loss: 0.5562\n",
            "Epoch 36/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8011 - loss: 0.4980 \n",
            "Epoch 37/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8267 - loss: 0.4413\n",
            "Epoch 38/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8523 - loss: 0.3975 \n",
            "Epoch 39/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8116 - loss: 0.4504\n",
            "Epoch 40/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8011 - loss: 0.4849\n",
            "Epoch 41/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8314 - loss: 0.4315\n",
            "Epoch 42/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8731 - loss: 0.3609\n",
            "Epoch 43/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8163 - loss: 0.4371 \n",
            "Epoch 44/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8419 - loss: 0.4161 \n",
            "Epoch 45/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8163 - loss: 0.4527 \n",
            "Epoch 46/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8116 - loss: 0.4085\n",
            "Epoch 47/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8419 - loss: 0.3909\n",
            "Epoch 48/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8267 - loss: 0.3995 \n",
            "Epoch 49/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8419 - loss: 0.3741 \n",
            "Epoch 50/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8523 - loss: 0.3751\n",
            "Epoch 51/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8419 - loss: 0.4066\n",
            "Epoch 52/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8011 - loss: 0.3853\n",
            "Epoch 53/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8419 - loss: 0.3591\n",
            "Epoch 54/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8059 - loss: 0.3692\n",
            "Epoch 55/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8419 - loss: 0.3728\n",
            "Epoch 56/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8419 - loss: 0.3488\n",
            "Epoch 57/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8419 - loss: 0.3585 \n",
            "Epoch 58/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8523 - loss: 0.3372 \n",
            "Epoch 59/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8314 - loss: 0.3645 \n",
            "Epoch 60/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8523 - loss: 0.3488\n",
            "Epoch 61/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8523 - loss: 0.3292 \n",
            "Epoch 62/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8419 - loss: 0.3425\n",
            "Epoch 63/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8314 - loss: 0.3783\n",
            "Epoch 64/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8267 - loss: 0.3509\n",
            "Epoch 65/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8419 - loss: 0.3753 \n",
            "Epoch 66/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8419 - loss: 0.3670\n",
            "Epoch 67/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8314 - loss: 0.3705\n",
            "Epoch 68/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8523 - loss: 0.3394\n",
            "Epoch 69/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8627 - loss: 0.3171 \n",
            "Epoch 70/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8419 - loss: 0.3370\n",
            "Epoch 71/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8210 - loss: 0.3708 \n",
            "Epoch 72/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8523 - loss: 0.3258 \n",
            "Epoch 73/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8523 - loss: 0.3426\n",
            "Epoch 74/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8059 - loss: 0.3791 \n",
            "Epoch 75/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8419 - loss: 0.3389 \n",
            "Epoch 76/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8267 - loss: 0.3328 \n",
            "Epoch 77/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8314 - loss: 0.3351\n",
            "Epoch 78/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8627 - loss: 0.3017 \n",
            "Epoch 79/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8163 - loss: 0.3368\n",
            "Epoch 80/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8371 - loss: 0.3093 \n",
            "Epoch 81/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8314 - loss: 0.3540 \n",
            "Epoch 82/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8419 - loss: 0.3328\n",
            "Epoch 83/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8523 - loss: 0.3198\n",
            "Epoch 84/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8314 - loss: 0.3346 \n",
            "Epoch 85/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8314 - loss: 0.3587\n",
            "Epoch 86/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8627 - loss: 0.3074 \n",
            "Epoch 87/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8466 - loss: 0.3431 \n",
            "Epoch 88/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8419 - loss: 0.3162\n",
            "Epoch 89/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8059 - loss: 0.3520 \n",
            "Epoch 90/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8419 - loss: 0.3462 \n",
            "Epoch 91/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8523 - loss: 0.3326 \n",
            "Epoch 92/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8523 - loss: 0.3175\n",
            "Epoch 93/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8419 - loss: 0.3452 \n",
            "Epoch 94/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8419 - loss: 0.3508\n",
            "Epoch 95/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8419 - loss: 0.3612\n",
            "Epoch 96/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8570 - loss: 0.3286 \n",
            "Epoch 97/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8419 - loss: 0.3491 \n",
            "Epoch 98/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8314 - loss: 0.3688\n",
            "Epoch 99/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8314 - loss: 0.3746 \n",
            "Epoch 100/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8314 - loss: 0.3504 \n",
            "Epoch 101/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8419 - loss: 0.3453\n",
            "Epoch 102/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8419 - loss: 0.3502\n",
            "Epoch 103/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8523 - loss: 0.3341\n",
            "Epoch 104/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8267 - loss: 0.3380 \n",
            "Epoch 105/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8163 - loss: 0.3300\n",
            "Epoch 106/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8419 - loss: 0.3141 \n",
            "Epoch 107/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8523 - loss: 0.3178\n",
            "Epoch 108/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8523 - loss: 0.3311 \n",
            "Epoch 109/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8523 - loss: 0.3206 \n",
            "Epoch 110/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8267 - loss: 0.3358\n",
            "Epoch 111/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8059 - loss: 0.3405\n",
            "Epoch 112/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8267 - loss: 0.3044\n",
            "Epoch 113/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8314 - loss: 0.3330\n",
            "Epoch 114/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8523 - loss: 0.3226\n",
            "Epoch 115/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8523 - loss: 0.3109 \n",
            "Epoch 116/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8419 - loss: 0.3414 \n",
            "Epoch 117/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8419 - loss: 0.3344\n",
            "Epoch 118/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8778 - loss: 0.3028\n",
            "Epoch 119/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8267 - loss: 0.3142\n",
            "Epoch 120/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8419 - loss: 0.3277\n",
            "Epoch 121/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8419 - loss: 0.3220 \n",
            "Epoch 122/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8210 - loss: 0.3397 \n",
            "Epoch 123/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8419 - loss: 0.3421\n",
            "Epoch 124/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8210 - loss: 0.3616\n",
            "Epoch 125/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8523 - loss: 0.3219 \n",
            "Epoch 126/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8419 - loss: 0.3355\n",
            "Epoch 127/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8570 - loss: 0.3343 \n",
            "Epoch 128/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8210 - loss: 0.3595 \n",
            "Epoch 129/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8419 - loss: 0.3244\n",
            "Epoch 130/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8523 - loss: 0.3028 \n",
            "Epoch 131/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8523 - loss: 0.3020 \n",
            "Epoch 132/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8523 - loss: 0.3139 \n",
            "Epoch 133/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8523 - loss: 0.3063\n",
            "Epoch 134/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8419 - loss: 0.3119\n",
            "Epoch 135/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8314 - loss: 0.3378 \n",
            "Epoch 136/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8523 - loss: 0.3105 \n",
            "Epoch 137/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8419 - loss: 0.3269\n",
            "Epoch 138/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8627 - loss: 0.3011\n",
            "Epoch 139/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8419 - loss: 0.3067\n",
            "Epoch 140/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8419 - loss: 0.3426 \n",
            "Epoch 141/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8419 - loss: 0.3427\n",
            "Epoch 142/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8419 - loss: 0.3529 \n",
            "Epoch 143/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8419 - loss: 0.3415\n",
            "Epoch 144/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8419 - loss: 0.3218 \n",
            "Epoch 145/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8314 - loss: 0.3412\n",
            "Epoch 146/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8419 - loss: 0.3207\n",
            "Epoch 147/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8523 - loss: 0.3144 \n",
            "Epoch 148/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8210 - loss: 0.3493\n",
            "Epoch 149/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8419 - loss: 0.3122\n",
            "Epoch 150/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8371 - loss: 0.3061\n",
            "Epoch 151/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8419 - loss: 0.3297\n",
            "Epoch 152/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8210 - loss: 0.3611 \n",
            "Epoch 153/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8210 - loss: 0.3480 \n",
            "Epoch 154/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8419 - loss: 0.3253\n",
            "Epoch 155/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8210 - loss: 0.3486\n",
            "Epoch 156/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8523 - loss: 0.3127\n",
            "Epoch 157/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8419 - loss: 0.3200\n",
            "Epoch 158/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8163 - loss: 0.3319 \n",
            "Epoch 159/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8371 - loss: 0.3013 \n",
            "Epoch 160/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8523 - loss: 0.3064 \n",
            "Epoch 161/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8523 - loss: 0.3122\n",
            "Epoch 162/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8523 - loss: 0.3073\n",
            "Epoch 163/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8210 - loss: 0.3376\n",
            "Epoch 164/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8419 - loss: 0.2925 \n",
            "Epoch 165/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8523 - loss: 0.3116\n",
            "Epoch 166/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8419 - loss: 0.3185\n",
            "Epoch 167/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8210 - loss: 0.3529 \n",
            "Epoch 168/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8059 - loss: 0.3464\n",
            "Epoch 169/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8419 - loss: 0.3172\n",
            "Epoch 170/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8210 - loss: 0.3500\n",
            "Epoch 171/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8419 - loss: 0.3144\n",
            "Epoch 172/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8314 - loss: 0.3442\n",
            "Epoch 173/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8523 - loss: 0.2941\n",
            "Epoch 174/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8314 - loss: 0.3416\n",
            "Epoch 175/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8419 - loss: 0.3216 \n",
            "Epoch 176/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8419 - loss: 0.3132\n",
            "Epoch 177/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8210 - loss: 0.3557\n",
            "Epoch 178/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8523 - loss: 0.3069\n",
            "Epoch 179/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8419 - loss: 0.3275 \n",
            "Epoch 180/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8419 - loss: 0.3142 \n",
            "Epoch 181/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8419 - loss: 0.3204 \n",
            "Epoch 182/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8210 - loss: 0.3588\n",
            "Epoch 183/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8419 - loss: 0.3170\n",
            "Epoch 184/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8210 - loss: 0.3549\n",
            "Epoch 185/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8627 - loss: 0.3015\n",
            "Epoch 186/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8059 - loss: 0.3438 \n",
            "Epoch 187/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8210 - loss: 0.3657 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Knowing the summary of the model..."
      ],
      "metadata": {
        "id": "T1ThjNg--KtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DlYmybJBrFrL",
        "outputId": "19413bee-9b83-4216-e10f-07955ee26ac8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │             \u001b[38;5;34m280\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m271,360\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)                  │           \u001b[38;5;34m8,995\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">280</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">271,360</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,995</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m841,907\u001b[0m (3.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">841,907</span> (3.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m280,635\u001b[0m (1.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">280,635</span> (1.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m561,272\u001b[0m (2.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">561,272</span> (2.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's plot accuracy v/s loss curve"
      ],
      "metadata": {
        "id": "sYVkpqPh-VcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plot_1 = pd.DataFrame(history.history)\n",
        "plt.figure(dpi=150, figsize = (5,3))\n",
        "plt.plot(plot_1)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(plot_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "Qcp1n9gvekcX",
        "outputId": "01aed68e-5b04-477e-9fa7-886c5f47a144"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7d0e2aaa3bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 750x450 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finally let's watch the output on giving **LLMs are** as an input..."
      ],
      "metadata": {
        "id": "B3E648yV-a5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "z-V0rPiU68l5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"abhishek\"\n",
        "\n",
        "for i in range(6):\n",
        "    previousword = text.split(\" \")[-1]\n",
        "    # tokenize\n",
        "    token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "    print(token_text)\n",
        "    # padding\n",
        "    padded_token_text = pad_sequences([token_text], maxlen=max_length, padding='pre')\n",
        "    print(padded_token_text)\n",
        "    # predict\n",
        "    position = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "    # print word at the particular position in tokenizer.word_index\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == position:\n",
        "            text = text + \" \" + word\n",
        "            print(text)\n",
        "            time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88sCwok_24ps",
        "outputId": "68fc5983-2879-4d5d-a0c3-351eb14e5554"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2]\n",
            "[[0 0 0 0 0 0 0 2]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "abhishek is\n",
            "[2, 3]\n",
            "[[0 0 0 0 0 0 2 3]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "abhishek is a\n",
            "[2, 3, 7]\n",
            "[[0 0 0 0 0 2 3 7]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "abhishek is a very\n",
            "[2, 3, 7, 10]\n",
            "[[ 0  0  0  0  2  3  7 10]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "abhishek is a very good\n",
            "[2, 3, 7, 10, 11]\n",
            "[[ 0  0  0  2  3  7 10 11]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "abhishek is a very good boy\n",
            "[2, 3, 7, 10, 11, 12]\n",
            "[[ 0  0  2  3  7 10 11 12]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "abhishek is a very good boy boy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I think it's performing well :)"
      ],
      "metadata": {
        "id": "brxH57Ho-mz_"
      }
    }
  ]
}